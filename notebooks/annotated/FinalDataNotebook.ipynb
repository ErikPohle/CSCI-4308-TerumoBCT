{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inner-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import gc\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60f629",
   "metadata": {},
   "source": [
    "### Read data from a feather binary file with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lasting-channel",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-72b1bc8d3412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/finaldata/fact_data.feather\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mstored\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "data = pd.read_feather(\"../data/finaldata/fact_data.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5661894",
   "metadata": {},
   "source": [
    "### Print the first ten rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e6fd5",
   "metadata": {},
   "source": [
    "### Print all rows in the DataFrame whose number_of_exception_alarms is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['number_of_exception_alarms'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313e25e",
   "metadata": {},
   "source": [
    "### Print some important columns' statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_alerts'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_donation_alarms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_exception_alarms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_temp_out_of_range_exceptions'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['alarm_id'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3c6e9",
   "metadata": {},
   "source": [
    "### Manually compute some statistics of the number_of_alerts columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate basic statistics col1\n",
    "print(data['number_of_alerts'].sum())\n",
    "print(data['number_of_alerts'].mean())\n",
    "print(data['number_of_alerts'].median())\n",
    "print(data['number_of_alerts'].std())\n",
    "print(data['number_of_alerts'].describe())\n",
    "# calculate correlation and covariance of dataframe\n",
    "#tmp1=data.cov()\n",
    "#tmp2=data.corr()\n",
    "\n",
    "#print(\"correlation:\\n \" + str(tmp1))\n",
    "#print(\"\\n\")\n",
    "#print(\"covariance:\\n \" + str(tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99145618",
   "metadata": {},
   "source": [
    "### Find all numeric columns and fill all NA/NAN values with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = data._get_numeric_data()\n",
    "tmp_data = tmp_data.fillna(0)\n",
    "tmp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb124bdc",
   "metadata": {},
   "source": [
    "### Split the whole dataset into a training set (50%) and a testing set (50%), and take the run_duration_minites as features and number_of_alerts as labels to train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(tmp_data, test_size=0.5)\n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(train_data['run_duration_minutes'].values.reshape(-1,1).astype('int'), train_data['number_of_alerts'].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74966538",
   "metadata": {},
   "source": [
    "### Compute and print the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy =\", model.score(train_data['run_duration_minutes'].values.reshape(-1, 1).astype('int'), train_data['number_of_alerts'].astype('int')))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12fb3c1",
   "metadata": {},
   "source": [
    "### Predict the number_of_alerts of the testing set and draw a figure with the training data and the testing data. In the fugure, the blue scatters indicate the training data points, and the red points are the preditions. In summary, this figure shows the relationships between run_duration_minutes and number_of_alerts for both training data and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sk = model.predict(train_data['run_duration_minutes'].values.reshape(-1, 1).astype('int'))\n",
    "                          \n",
    "plt.clf()\n",
    "plt.scatter(train_data['run_duration_minutes'].values.reshape(-1, 1).astype('int'), train_data['number_of_alerts'].astype('int'))\n",
    "plt.scatter(test_data['run_duration_minutes'].values.reshape(-1, 1).astype('int'), y_pred_sk, c=\"red\")\n",
    "plt.xlabel(\"Run Duration Minutes\")\n",
    "plt.ylabel(\"Number of Alerts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data._get_numeric_data()\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(new_data.values.reshape(-1,1).astype('int'), new_data.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-monster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
